{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd50e8f-cefd-41b4-839c-3b62df777f68",
   "metadata": {},
   "source": [
    "# Первая генерация рекомендаций"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8adb9a-5926-4a54-8a1b-5aa984560326",
   "metadata": {},
   "source": [
    "## Вывод предпочтений пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "917abf8c-ced7-409a-bb25-2a5c95957315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             tag  percent  likes\n",
      "0                    Мультфильмы      0.0      0\n",
      "1                    Развлечения      0.0      0\n",
      "2                          Хобби      0.0      0\n",
      "3                       Животные      0.0      0\n",
      "4                         Разное      0.0      0\n",
      "5                      Лайфстайл      0.0      0\n",
      "6                   Телепередачи      0.0      0\n",
      "7                          Спорт      0.0      0\n",
      "8                   Недвижимость      0.0      0\n",
      "9                        Сериалы      0.0      0\n",
      "10                         Детям      0.0      0\n",
      "11                        Музыка      0.0      0\n",
      "12                          Юмор      0.0      0\n",
      "13                     Авто-мото      0.0      0\n",
      "14                  Сад и огород      0.0      0\n",
      "15                        Фильмы      0.0      0\n",
      "16                     Видеоигры      0.0      0\n",
      "17                         Наука      0.0      0\n",
      "18                   Путешествия      0.0      0\n",
      "19         Технологии и интернет      0.0      0\n",
      "20                      Лайфхаки      0.0      0\n",
      "21                      Культура      0.0      0\n",
      "22   Обзоры и распаковки товаров      0.0      0\n",
      "23                      Обучение      0.0      0\n",
      "24                      Здоровье      0.0      0\n",
      "25               Охота и рыбалка      0.0      0\n",
      "26        Строительство и ремонт      0.0      0\n",
      "27                         Аниме      0.0      0\n",
      "28                     Эзотерика      0.0      0\n",
      "29                           Еда      0.0      0\n",
      "30                       UNKNOWN      0.0      0\n",
      "31                      Интервью      0.0      0\n",
      "32  Бизнес и предпринимательство      0.0      0\n",
      "33        Техника и оборудование      0.0      0\n",
      "34                    Психология      0.0      0\n",
      "35                       Красота      0.0      0\n",
      "36                       Природа      0.0      0\n",
      "37                        Дизайн      0.0      0\n",
      "38                    Аудиокниги      0.0      0\n",
      "39                         Аудио      0.0      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загружаем DataFrame из файла Parquet\n",
    "df = pd.read_parquet('users/user0_tags.parquet')\n",
    "\n",
    "# Выводим первые 5 строк\n",
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f856355-bea5-4831-b4f7-42edc0f5ece6",
   "metadata": {},
   "source": [
    "## Стандартная генерация исходя из предпочтений пользователя (т.к. пользователь холодный, то и выводится будут с платформы популярные категории)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "478f2e9b-fed3-4c58-bf29-f167e0569818",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               video_id  \\\n",
      "0  e0eedb0a-2468-4193-8b76-2c41fd9af529   \n",
      "1  15761c10-583a-4e3a-84db-f7f48fa94782   \n",
      "2  dde49c8e-db30-427f-bef5-3f94701ede0b   \n",
      "3  82bf16f6-9764-4582-9607-fe98d7c6ceba   \n",
      "4  f0086c15-3718-411b-ad40-bc1fb67f67cb   \n",
      "5  58aac622-479c-4011-ae6d-1001b52a9a50   \n",
      "6  cf26723f-121c-448f-ae64-1b2430c4a854   \n",
      "7  8dfb4533-dd5c-432a-aefe-fa6e1c18f3bc   \n",
      "8  9ba1f34d-935a-4c43-a5ce-ab78cdd9f407   \n",
      "9  11449640-6224-4f1c-8cef-38270b1a248b   \n",
      "\n",
      "                                               title  \\\n",
      "0              Отчаянные Домохозяйки 1 сезон 3 серия   \n",
      "1  Сериал Презумпция невиновности – 1 сезон 1 сер...   \n",
      "2  Магическая битва 2 сезон 15 серия (аниме-сериа...   \n",
      "3  Gravity Falls - (2 сезон) 4 серия \"Носочная оп...   \n",
      "4                      10 глупых вопросов ШОУРАННЕРУ   \n",
      "5  Новое Простоквашино – 11 серия – Вишнёвая Феер...   \n",
      "6  Домой - любой ценой. Мужское / Женское. Самые ...   \n",
      "7                             Самые необычные КНИГИ!   \n",
      "8  Возрастающей или убывающей является функция f(...   \n",
      "9  Пора по пабам: девушки предпочитают пойти на с...   \n",
      "\n",
      "             v_pub_datetime   category_id  \n",
      "0 2024-01-22 11:34:26+03:00       Сериалы  \n",
      "1 2024-06-13 19:39:51+03:00       Сериалы  \n",
      "2 2024-01-26 17:31:24+03:00        Разное  \n",
      "3 2017-12-28 20:32:18+03:00   Мультфильмы  \n",
      "4 2024-01-18 19:00:12+03:00      Интервью  \n",
      "5 2022-11-26 20:20:32+03:00   Мультфильмы  \n",
      "6 2023-01-28 15:37:32+03:00  Телепередачи  \n",
      "7 2023-01-30 18:24:59+03:00   Развлечения  \n",
      "8 2023-12-07 14:04:08+03:00      Обучение  \n",
      "9 2024-07-03 12:04:51+03:00   Развлечения  \n",
      "Данные успешно сохранены в файл final_videos_info.parquet.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Загрузка модели\n",
    "model = joblib.load('random_forest_model.joblib')\n",
    "\n",
    "# Загрузка данных из файлов\n",
    "filtred_df = pd.read_parquet('tags-filtered.parquet')\n",
    "logs_df = pd.read_parquet('logsV02.parquet')\n",
    "tags_df = pd.read_parquet('users/user0_tags.parquet')\n",
    "regions_df = pd.read_parquet('users/user0_regions.parquet')\n",
    "city_df = pd.read_parquet('users/user0_city.parquet')\n",
    "additional_df = pd.read_parquet('parquet-filtered/filtred.parquet')\n",
    "\n",
    "# Объединение данных по video_id\n",
    "merged_df = pd.merge(filtred_df, logs_df, on='video_id', how='inner')\n",
    "\n",
    "# Ограничиваемся первыми 1000 записями\n",
    "merged_df = merged_df.head(1000)\n",
    "\n",
    "# Признаки\n",
    "features = ['category_id', 'v_likes', 'v_dislikes',\n",
    "            'v_frac_avg_watchtime_1_day_duration',\n",
    "            'v_frac_avg_watchtime_7_day_duration',\n",
    "            'v_frac_avg_watchtime_30_day_duration']\n",
    "\n",
    "# Преобразование категориальных переменных для новых данных\n",
    "X_new = pd.get_dummies(merged_df[features], drop_first=True)\n",
    "\n",
    "# Обработка данных: замена бесконечных значений и NaN\n",
    "X_new.replace([float('inf'), float('-inf')], pd.NA, inplace=True)\n",
    "X_new.dropna(inplace=True)\n",
    "\n",
    "# Сохранение индексов оставшихся строк\n",
    "valid_indices = X_new.index\n",
    "\n",
    "# Обеспечение соответствия признаков модели\n",
    "X_new = X_new.reindex(columns=model.feature_names_in_, fill_value=0)\n",
    "\n",
    "# Выполнение предсказаний\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "# Создание нового столбца с предсказанными значениями только для действительных индексов\n",
    "merged_df.loc[valid_indices, 'predicted_popularity'] = predictions\n",
    "\n",
    "# Удаление дубликатов по video_id\n",
    "unique_videos = merged_df.drop_duplicates(subset='video_id')\n",
    "\n",
    "# Сортировка по предсказанной популярности\n",
    "unique_videos = unique_videos.sort_values(by='predicted_popularity', ascending=False)\n",
    "\n",
    "# Поиск максимальных 3 значений percent с тегом\n",
    "top_tags = tags_df.nlargest(3, 'percent')\n",
    "\n",
    "# Список для хранения финальных видео\n",
    "final_video_ids = []\n",
    "\n",
    "# Выбор случайного числа для изменения выборки\n",
    "random.seed(time.time())\n",
    "\n",
    "# Поиск двух популярных видео для каждого из топовых тегов\n",
    "for tag in top_tags['tag']:\n",
    "    # Находим все видео с данным тегом\n",
    "    videos_with_tag = unique_videos[unique_videos['category_id'].str.contains(tag, na=False)]\n",
    "    \n",
    "    if not videos_with_tag.empty:\n",
    "        # Выбор до 2 видео с этим тегом\n",
    "        selected_videos = videos_with_tag.sample(n=min(2, len(videos_with_tag)), random_state=random.randint(0, 100))\n",
    "        final_video_ids.extend(selected_videos['video_id'].tolist())\n",
    "\n",
    "# Если всё ещё не достигли 10 видео, добавляем случайные видео из других категорий\n",
    "remaining_slots = 10 - len(final_video_ids)\n",
    "\n",
    "if remaining_slots > 0:\n",
    "    popular_others = unique_videos[~unique_videos['video_id'].isin(final_video_ids)].sample(\n",
    "        n=min(remaining_slots, len(unique_videos[~unique_videos['video_id'].isin(final_video_ids)])),\n",
    "              random_state=random.randint(0, 100))\n",
    "        \n",
    "    final_video_ids.extend(popular_others['video_id'].tolist())\n",
    "\n",
    "# Удаляем дубликаты, если они есть\n",
    "final_video_ids = list(set(final_video_ids))\n",
    "\n",
    "# Получаем финальные 10 видео\n",
    "final_video_ids = final_video_ids[:10]\n",
    "\n",
    "# Проверка на наличие файла security.parquet и его содержимого\n",
    "try:\n",
    "    security_df = pd.read_parquet('security.parquet')\n",
    "except ValueError:\n",
    "    # Если файл не существует или пуст, то создаем пустая DataFrame\n",
    "    security_df = pd.DataFrame(columns=['video_id'])\n",
    "\n",
    "if security_df.empty:\n",
    "    # Если файл пуст, просто используем финальные video_id\n",
    "    existing_video_ids = set()  # Пустое множество, так как ничего нет в security.parquet\n",
    "else:\n",
    "    existing_video_ids = set(security_df['video_id'])\n",
    "\n",
    "# Генерация новых video_id в случае совпадений\n",
    "while any(video_id in existing_video_ids for video_id in final_video_ids):\n",
    "    # Ищем альтернативные video_id, пока все не будут уникальными\n",
    "    additional_videos = unique_videos[~unique_videos['video_id'].isin(final_video_ids)].sample(\n",
    "    n=len(final_video_ids), random_state=random.randint(0, 100))\n",
    "    \n",
    "    final_video_ids = additional_videos['video_id'].tolist()\n",
    "    final_video_ids = list(set(final_video_ids))[:10]  # Убедимся, что оставим только 10\n",
    "\n",
    "# Получаем данные о финальных видео\n",
    "final_videos = unique_videos[unique_videos['video_id'].isin(final_video_ids)]\n",
    "\n",
    "# Объединяем с дополнительным DataFrame для получения title и v_pub_datetime\n",
    "final_videos_info = pd.merge(final_videos, additional_df[['video_id', 'title', 'v_pub_datetime']],\n",
    "                              on='video_id', how='left')\n",
    "\n",
    "# Сохранение итоговых video_id в файл security.parquet\n",
    "final_video_ids_df = pd.DataFrame(final_video_ids, columns=['video_id'])\n",
    "\n",
    "# Добавляем новые video_id в security.parquet, если они уникальны\n",
    "new_ids_to_add = final_video_ids_df[~final_video_ids_df['video_id'].isin(existing_video_ids)]\n",
    "\n",
    "if not new_ids_to_add.empty:\n",
    "    # Объединяем с существующими данными\n",
    "    updated_security_df = pd.concat([security_df, new_ids_to_add], ignore_index=True)\n",
    "    updated_security_df.to_parquet('security.parquet', index=False)\n",
    "\n",
    "# Вывод финальных видео\n",
    "print(final_videos_info[['video_id', 'title', 'v_pub_datetime', 'category_id']])\n",
    "# Сохранение данных в файл final_videos_info.parquet\n",
    "final_videos_info[['video_id', 'title', 'v_pub_datetime', 'category_id']].to_parquet('final_videos_info.parquet', index=False)\n",
    "\n",
    "print(\"Данные успешно сохранены в файл final_videos_info.parquet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790eda2-4b1b-48d9-9c4e-10cb2bef0762",
   "metadata": {},
   "source": [
    "## Пользователь ставит лайк, дизлайк на видео"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c315b0-395a-44df-a32e-45bf583f63d0",
   "metadata": {},
   "source": [
    "## Сбор и сохранение результатов первой выдачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef3622b4-f348-4ff7-9292-7b0c54354435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Значение лайка для видео (0 или 1) [Отчаянные Домохозяйки 1 сезон 3 серия] категории [Сериалы]:  1\n",
      "Значение дизлайка для видео (0 или 1) [Отчаянные Домохозяйки 1 сезон 3 серия] категории [Сериалы]:  0\n",
      "Значение лайка для видео (0 или 1) [Сериал Презумпция невиновности – 1 сезон 1 серия  / Presumed Innocent] категории [Сериалы]:  1\n",
      "Значение дизлайка для видео (0 или 1) [Сериал Презумпция невиновности – 1 сезон 1 серия  / Presumed Innocent] категории [Сериалы]:  0\n",
      "Значение лайка для видео (0 или 1) [Магическая битва 2 сезон 15 серия (аниме-сериал, 2023)] категории [Разное]:  1\n",
      "Значение дизлайка для видео (0 или 1) [Магическая битва 2 сезон 15 серия (аниме-сериал, 2023)] категории [Разное]:  0\n",
      "Значение лайка для видео (0 или 1) [Gravity Falls - (2 сезон) 4 серия \"Носочная опера\"] категории [Мультфильмы]:  0\n",
      "Значение дизлайка для видео (0 или 1) [Gravity Falls - (2 сезон) 4 серия \"Носочная опера\"] категории [Мультфильмы]:  0\n",
      "Значение лайка для видео (0 или 1) [10 глупых вопросов ШОУРАННЕРУ] категории [Интервью]:  0\n",
      "Значение дизлайка для видео (0 или 1) [10 глупых вопросов ШОУРАННЕРУ] категории [Интервью]:  0\n",
      "Значение лайка для видео (0 или 1) [Новое Простоквашино – 11 серия – Вишнёвая Феерия – Союзмультфильм HD] категории [Мультфильмы]:  0\n",
      "Значение дизлайка для видео (0 или 1) [Новое Простоквашино – 11 серия – Вишнёвая Феерия – Союзмультфильм HD] категории [Мультфильмы]:  0\n",
      "Значение лайка для видео (0 или 1) [Домой - любой ценой. Мужское / Женское. Самые драматичные моменты выпуска от 18.12.2020] категории [Телепередачи]:  0\n",
      "Значение дизлайка для видео (0 или 1) [Домой - любой ценой. Мужское / Женское. Самые драматичные моменты выпуска от 18.12.2020] категории [Телепередачи]:  0\n",
      "Значение лайка для видео (0 или 1) [Самые необычные КНИГИ!] категории [Развлечения]:  0\n",
      "Значение дизлайка для видео (0 или 1) [Самые необычные КНИГИ!] категории [Развлечения]:  0\n",
      "Значение лайка для видео (0 или 1) [Возрастающей или убывающей является функция f(g(x)), если g(x)=3-2x] категории [Обучение]:  0\n",
      "Значение дизлайка для видео (0 или 1) [Возрастающей или убывающей является функция f(g(x)), если g(x)=3-2x] категории [Обучение]:  0\n",
      "Значение лайка для видео (0 или 1) [Пора по пабам: девушки предпочитают пойти на свидании в ирландский паб | пародия «Пора По Пиву»] категории [Развлечения]:  0\n",
      "Значение дизлайка для видео (0 или 1) [Пора по пабам: девушки предпочитают пойти на свидании в ирландский паб | пародия «Пора По Пиву»] категории [Развлечения]:  0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Загрузка данных из файла final_videos_info.parquet\n",
    "final_videos_info = pd.read_parquet('final_videos_info.parquet')\n",
    "\n",
    "# Считывание нужных столбцов\n",
    "video_data = final_videos_info[['video_id', 'title', 'category_id']]\n",
    "\n",
    "# Инициализация списка для итоговых значений\n",
    "aggregated = []\n",
    "\n",
    "# Запрос значений лайков и дизлайков\n",
    "for index, row in video_data.iterrows():\n",
    "    video_id = row['video_id']\n",
    "    title = row['title']\n",
    "    category_id = row['category_id']\n",
    "    \n",
    "    total_likes = int(input(f\"Значение лайка для видео (0 или 1) [{title}] категории [{category_id}]: \"))\n",
    "    total_dislikes = int(input(f\"Значение дизлайка для видео (0 или 1) [{title}] категории [{category_id}]: \"))\n",
    "    \n",
    "    aggregated.append({\n",
    "        'uid': video_id,\n",
    "        'total_likes': total_likes,\n",
    "        'total_dislikes': total_dislikes\n",
    "    })\n",
    "\n",
    "# Сохранение итоговых значений в файл JSON\n",
    "with open('aggregated_data.json', 'w') as json_file:\n",
    "    json.dump(aggregated, json_file, indent=4)\n",
    "\n",
    "# Вывод содержимого файла JSON\n",
    "with open('aggregated_data.json', 'r') as json_file:\n",
    "    content = json_file.read()\n",
    "    #print(\"Содержимое файла aggregated_data.json:\")\n",
    "    #print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e76691-e67c-4104-ba11-2401eb3e1f81",
   "metadata": {},
   "source": [
    "## Подсчёт интересов пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6119edfb-2ae8-44eb-8144-12690e77b3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лайки и процентное соотношение сохранены в файл users/user0_tags.parquet.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Загрузка данных из файлов\n",
    "tags_df = pd.read_parquet('users/user0_tags.parquet')\n",
    "categories_df = pd.read_parquet('tags-filtered.parquet')\n",
    "\n",
    "# Загрузка данных из файла aggregated_data.json\n",
    "with open('aggregated_data.json', 'r') as json_file:\n",
    "    aggregated = json.load(json_file)\n",
    "\n",
    "# Инициализация словаря для накопления лайков и дизлайков по категориям\n",
    "category_likes = {}\n",
    "\n",
    "# Суммирование лайков и дизлайков для каждой категории\n",
    "for item in aggregated:\n",
    "    video_id = item['uid']\n",
    "    \n",
    "    # Получение category_id по video_id\n",
    "    category_info = categories_df[categories_df['video_id'] == video_id]\n",
    "    \n",
    "    if not category_info.empty:\n",
    "        category_id = category_info['category_id'].values[0]\n",
    "        \n",
    "        if category_id not in category_likes:\n",
    "            category_likes[category_id] = {'likes': 0, 'dislikes': 0}\n",
    "        \n",
    "        category_likes[category_id]['likes'] += item['total_likes']\n",
    "        category_likes[category_id]['dislikes'] += item['total_dislikes']\n",
    "\n",
    "# Обновление тегов на основе накопленных значений\n",
    "for category_id, counts in category_likes.items():\n",
    "    tag_index = tags_df[tags_df['tag'] == category_id].index\n",
    "    \n",
    "    if not tag_index.empty:\n",
    "        tag_row = tag_index[0]\n",
    "        \n",
    "        # Обновляем likes в tags_df\n",
    "        tags_df.at[tag_row, 'likes'] += counts['likes']\n",
    "        # Учитываем дизлайки\n",
    "        tags_df.at[tag_row, 'likes'] = max(0, tags_df.at[tag_row, 'likes'] - counts['dislikes'])\n",
    "\n",
    "# Функция для расчета процентов\n",
    "def calculate_percentages(df):\n",
    "    total_likes = df['likes'].sum()\n",
    "    if total_likes > 0:\n",
    "        df['percent'] = (df['likes'] / total_likes * 100).fillna(0)\n",
    "    else:\n",
    "        df['percent'] = 0\n",
    "    return df\n",
    "\n",
    "# Расчет лайков и процентов для тегов\n",
    "tags_df = calculate_percentages(tags_df)\n",
    "\n",
    "# Сохранение обновленного DataFrame обратно в файл\n",
    "tags_df.to_parquet('users/user0_tags.parquet', index=False)\n",
    "\n",
    "print(\"Лайки и процентное соотношение сохранены в файл users/user0_tags.parquet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f72bfc8-0955-43de-8d09-8ec4f6065b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             tag    percent  likes\n",
      "0                    Мультфильмы   0.000000      0\n",
      "1                    Развлечения   0.000000      0\n",
      "2                          Хобби   0.000000      0\n",
      "3                       Животные   0.000000      0\n",
      "4                         Разное  33.333333      1\n",
      "5                      Лайфстайл   0.000000      0\n",
      "6                   Телепередачи   0.000000      0\n",
      "7                          Спорт   0.000000      0\n",
      "8                   Недвижимость   0.000000      0\n",
      "9                        Сериалы  66.666667      2\n",
      "10                         Детям   0.000000      0\n",
      "11                        Музыка   0.000000      0\n",
      "12                          Юмор   0.000000      0\n",
      "13                     Авто-мото   0.000000      0\n",
      "14                  Сад и огород   0.000000      0\n",
      "15                        Фильмы   0.000000      0\n",
      "16                     Видеоигры   0.000000      0\n",
      "17                         Наука   0.000000      0\n",
      "18                   Путешествия   0.000000      0\n",
      "19         Технологии и интернет   0.000000      0\n",
      "20                      Лайфхаки   0.000000      0\n",
      "21                      Культура   0.000000      0\n",
      "22   Обзоры и распаковки товаров   0.000000      0\n",
      "23                      Обучение   0.000000      0\n",
      "24                      Здоровье   0.000000      0\n",
      "25               Охота и рыбалка   0.000000      0\n",
      "26        Строительство и ремонт   0.000000      0\n",
      "27                         Аниме   0.000000      0\n",
      "28                     Эзотерика   0.000000      0\n",
      "29                           Еда   0.000000      0\n",
      "30                       UNKNOWN   0.000000      0\n",
      "31                      Интервью   0.000000      0\n",
      "32  Бизнес и предпринимательство   0.000000      0\n",
      "33        Техника и оборудование   0.000000      0\n",
      "34                    Психология   0.000000      0\n",
      "35                       Красота   0.000000      0\n",
      "36                       Природа   0.000000      0\n",
      "37                        Дизайн   0.000000      0\n",
      "38                    Аудиокниги   0.000000      0\n",
      "39                         Аудио   0.000000      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загружаем DataFrame из файла Parquet\n",
    "df = pd.read_parquet('users/user0_tags.parquet')\n",
    "\n",
    "# Выводим первые 5 строк\n",
    "print(df.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cf0ca8-a91b-4c12-885f-e5e8339ff1bc",
   "metadata": {},
   "source": [
    "# Вывод рекомендация исходя из интересов пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "daf2d828-e5c8-4359-a11f-8bb95eafe416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               video_id  \\\n",
      "0  3c43a697-fa07-48ec-91ac-80f5706252b3   \n",
      "1  7644ebc0-65f9-4113-921e-98629a5ff1bc   \n",
      "2  12c0dcb0-eed5-4c10-b734-df6a90de6112   \n",
      "3  f603a751-9223-4157-b248-9250b4379cce   \n",
      "4  bcd43ee0-425a-4d3a-aa00-09a80bb120f7   \n",
      "5  4126d9a8-955e-454f-9997-6ba52c698906   \n",
      "6  53d7fd98-ba32-4913-86a9-11ee1f01948f   \n",
      "7  e405ebb5-9091-4b46-9552-2810c274a58d   \n",
      "8  1774ca13-4edc-4816-b999-e7c3d279e91d   \n",
      "9  478cceab-4fff-4b16-b65a-caaf91bd23c6   \n",
      "\n",
      "                                               title  \\\n",
      "0  Хороший доктор – 2 сезон 4 серия «Крепкий ореш...   \n",
      "1  Хороший доктор – 4 сезон 20 серия «Начнём» / T...   \n",
      "2  Обоюдное согласие 1 Сезон _ 3 Серия _ Сюжет и ...   \n",
      "3      Гравити Фолз (2 сезон 18 серия) – Апокалипсис   \n",
      "4  Военнослужащий ищет женщину в соку. Давай поже...   \n",
      "5              Король: Вечный монарх 1 сезон 1 серия   \n",
      "6  Минифорс. Сила динозавров, 51 серия. Лорд полу...   \n",
      "7                              С праздником 8 марта!   \n",
      "8  СУПЕР СРЕДСТВО ,👍 кислородный пятновыводитель ...   \n",
      "9                           нолик орёт Csuрo Effects   \n",
      "\n",
      "             v_pub_datetime   category_id  \n",
      "0 2024-03-28 20:00:30+03:00       Сериалы  \n",
      "1 2024-03-30 22:52:11+03:00       Сериалы  \n",
      "2 2024-07-07 10:29:24+03:00       Сериалы  \n",
      "3 2023-09-06 22:31:38+03:00   Мультфильмы  \n",
      "4 2024-05-21 16:05:04+03:00  Телепередачи  \n",
      "5 2024-02-14 18:09:35+03:00       Сериалы  \n",
      "6 2023-12-16 13:28:47+03:00   Мультфильмы  \n",
      "7 2024-03-08 18:39:49+03:00        Разное  \n",
      "8 2023-02-16 11:31:58+03:00      Лайфхаки  \n",
      "9 2023-12-22 06:13:04+03:00        Разное  \n",
      "Данные успешно сохранены в файл final_videos_info.parquet.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Загрузка модели\n",
    "model = joblib.load('random_forest_model.joblib')\n",
    "\n",
    "# Загрузка данных из файлов\n",
    "filtred_df = pd.read_parquet('tags-filtered.parquet')\n",
    "logs_df = pd.read_parquet('logsV02.parquet')\n",
    "tags_df = pd.read_parquet('users/user0_tags.parquet')\n",
    "regions_df = pd.read_parquet('users/user0_regions.parquet')\n",
    "city_df = pd.read_parquet('users/user0_city.parquet')\n",
    "additional_df = pd.read_parquet('parquet-filtered/filtred.parquet')\n",
    "\n",
    "# Объединение данных по video_id\n",
    "merged_df = pd.merge(filtred_df, logs_df, on='video_id', how='inner')\n",
    "\n",
    "# Ограничиваемся первыми 1000 записями\n",
    "merged_df = merged_df.head(1000)\n",
    "\n",
    "# Признаки\n",
    "features = ['category_id', 'v_likes', 'v_dislikes',\n",
    "            'v_frac_avg_watchtime_1_day_duration',\n",
    "            'v_frac_avg_watchtime_7_day_duration',\n",
    "            'v_frac_avg_watchtime_30_day_duration']\n",
    "\n",
    "# Преобразование категориальных переменных для новых данных\n",
    "X_new = pd.get_dummies(merged_df[features], drop_first=True)\n",
    "\n",
    "# Обработка данных: замена бесконечных значений и NaN\n",
    "X_new.replace([float('inf'), float('-inf')], pd.NA, inplace=True)\n",
    "X_new.dropna(inplace=True)\n",
    "\n",
    "# Сохранение индексов оставшихся строк\n",
    "valid_indices = X_new.index\n",
    "\n",
    "# Обеспечение соответствия признаков модели\n",
    "X_new = X_new.reindex(columns=model.feature_names_in_, fill_value=0)\n",
    "\n",
    "# Выполнение предсказаний\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "# Создание нового столбца с предсказанными значениями только для действительных индексов\n",
    "merged_df.loc[valid_indices, 'predicted_popularity'] = predictions\n",
    "\n",
    "# Удаление дубликатов по video_id\n",
    "unique_videos = merged_df.drop_duplicates(subset='video_id')\n",
    "\n",
    "# Сортировка по предсказанной популярности\n",
    "unique_videos = unique_videos.sort_values(by='predicted_popularity', ascending=False)\n",
    "\n",
    "# Поиск максимальных 3 значений percent с тегом\n",
    "top_tags = tags_df.nlargest(3, 'percent')\n",
    "\n",
    "# Список для хранения финальных видео\n",
    "final_video_ids = []\n",
    "\n",
    "# Выбор случайного числа для изменения выборки\n",
    "random.seed(time.time())\n",
    "\n",
    "# Поиск двух популярных видео для каждого из топовых тегов\n",
    "for tag in top_tags['tag']:\n",
    "    # Находим все видео с данным тегом\n",
    "    videos_with_tag = unique_videos[unique_videos['category_id'].str.contains(tag, na=False)]\n",
    "    \n",
    "    if not videos_with_tag.empty:\n",
    "        # Выбор до 2 видео с этим тегом\n",
    "        selected_videos = videos_with_tag.sample(n=min(2, len(videos_with_tag)), random_state=random.randint(0, 100))\n",
    "        final_video_ids.extend(selected_videos['video_id'].tolist())\n",
    "\n",
    "# Если всё ещё не достигли 10 видео, добавляем случайные видео из других категорий\n",
    "remaining_slots = 10 - len(final_video_ids)\n",
    "\n",
    "if remaining_slots > 0:\n",
    "    popular_others = unique_videos[~unique_videos['video_id'].isin(final_video_ids)].sample(\n",
    "        n=min(remaining_slots, len(unique_videos[~unique_videos['video_id'].isin(final_video_ids)])),\n",
    "              random_state=random.randint(0, 100))\n",
    "        \n",
    "    final_video_ids.extend(popular_others['video_id'].tolist())\n",
    "\n",
    "# Удаляем дубликаты, если они есть\n",
    "final_video_ids = list(set(final_video_ids))\n",
    "\n",
    "# Получаем финальные 10 видео\n",
    "final_video_ids = final_video_ids[:10]\n",
    "\n",
    "# Проверка на наличие файла security.parquet и его содержимого\n",
    "try:\n",
    "    security_df = pd.read_parquet('security.parquet')\n",
    "except ValueError:\n",
    "    # Если файл не существует или пуст, то создаем пустая DataFrame\n",
    "    security_df = pd.DataFrame(columns=['video_id'])\n",
    "\n",
    "if security_df.empty:\n",
    "    # Если файл пуст, просто используем финальные video_id\n",
    "    existing_video_ids = set()  # Пустое множество, так как ничего нет в security.parquet\n",
    "else:\n",
    "    existing_video_ids = set(security_df['video_id'])\n",
    "\n",
    "# Генерация новых video_id в случае совпадений\n",
    "while any(video_id in existing_video_ids for video_id in final_video_ids):\n",
    "    # Ищем альтернативные video_id, пока все не будут уникальными\n",
    "    additional_videos = unique_videos[~unique_videos['video_id'].isin(final_video_ids)].sample(\n",
    "    n=len(final_video_ids), random_state=random.randint(0, 100))\n",
    "    \n",
    "    final_video_ids = additional_videos['video_id'].tolist()\n",
    "    final_video_ids = list(set(final_video_ids))[:10]  # Убедимся, что оставим только 10\n",
    "\n",
    "# Получаем данные о финальных видео\n",
    "final_videos = unique_videos[unique_videos['video_id'].isin(final_video_ids)]\n",
    "\n",
    "# Объединяем с дополнительным DataFrame для получения title и v_pub_datetime\n",
    "final_videos_info = pd.merge(final_videos, additional_df[['video_id', 'title', 'v_pub_datetime']],\n",
    "                              on='video_id', how='left')\n",
    "\n",
    "# Сохранение итоговых video_id в файл security.parquet\n",
    "final_video_ids_df = pd.DataFrame(final_video_ids, columns=['video_id'])\n",
    "\n",
    "# Добавляем новые video_id в security.parquet, если они уникальны\n",
    "new_ids_to_add = final_video_ids_df[~final_video_ids_df['video_id'].isin(existing_video_ids)]\n",
    "\n",
    "if not new_ids_to_add.empty:\n",
    "    # Объединяем с существующими данными\n",
    "    updated_security_df = pd.concat([security_df, new_ids_to_add], ignore_index=True)\n",
    "    updated_security_df.to_parquet('security.parquet', index=False)\n",
    "\n",
    "# Вывод финальных видео\n",
    "print(final_videos_info[['video_id', 'title', 'v_pub_datetime', 'category_id']])\n",
    "# Сохранение данных в файл final_videos_info.parquet\n",
    "final_videos_info[['video_id', 'title', 'v_pub_datetime', 'category_id']].to_parquet('final_videos_info.parquet', index=False)\n",
    "\n",
    "print(\"Данные успешно сохранены в файл final_videos_info.parquet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca40c8-f4ad-4bcc-8269-4f82f137ed7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce75a2-98b4-4655-a1f0-a3295310a6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce690b0-0293-49d0-ab06-3268972fcfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f3819f-673d-46d4-9791-44d338d9ff6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d370b788-8515-4f4a-be08-ef15e94e9df5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
